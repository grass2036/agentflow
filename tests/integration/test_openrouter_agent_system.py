#!/usr/bin/env python3
"""
OpenRouter AI Agent System Integration Test
Tests the complete integration of OpenRouter with the AI Agent Orchestrator
"""

import asyncio
import json
import sys
import os
from datetime import datetime

# Add parent directory to path for imports
sys.path.insert(0, os.path.join(os.path.dirname(__file__), '../..'))

from ai_agent.core.orchestrator import AgentOrchestrator
from ai_agent.core.types import (
    ProjectConfig, TechStack, PlatformType, ProjectComplexity, 
    TaskPriority, AgentRole
)
from ai_agent.core.task import create_task

async def test_openrouter_agent_system():
    """æµ‹è¯•OpenRouter AI Agentç³»ç»Ÿé›†æˆ"""
    print("ğŸš€ OpenRouter AI Agent System Integration Test")
    print("=" * 80)
    
    # Test 1: åˆ›å»ºä½¿ç”¨OpenRouterçš„åè°ƒå™¨
    print("\nğŸ“‹ Test 1: Creating OpenRouter-Enabled Orchestrator")
    print("-" * 60)
    
    try:
        # æµ‹è¯•å…è´¹æ¨¡å‹ä¼˜å…ˆ
        orchestrator_free = AgentOrchestrator(use_openrouter=True, prefer_free_models=True)
        print("âœ… OpenRouter Orchestrator (Free Models) created successfully")
        
        # æµ‹è¯•ä»˜è´¹æ¨¡å‹ä¼˜å…ˆ
        orchestrator_premium = AgentOrchestrator(use_openrouter=True, prefer_free_models=False)
        print("âœ… OpenRouter Orchestrator (Premium Models) created successfully")
        
    except Exception as e:
        print(f"âŒ Failed to create orchestrator: {e}")
        return False
    
    # Test 2: æµ‹è¯•Agentè¿æ¥
    print(f"\nğŸ’» Test 2: Testing Agent Connections")
    print("-" * 60)
    
    connection_results = orchestrator_free.test_all_agent_connections()
    successful_connections = 0
    
    for role, result in connection_results.items():
        if result.get("success", False):
            print(f"âœ… {role}: Connected successfully")
            successful_connections += 1
        else:
            print(f"âŒ {role}: Connection failed - {result.get('error', 'Unknown error')}")
    
    print(f"ğŸ“Š Connection Summary: {successful_connections}/{len(connection_results)} agents connected")
    
    if successful_connections == 0:
        print("âŒ No agents connected successfully. Check API key and configuration.")
        return False
    
    # Test 3: å•ä¸ªAgentä»»åŠ¡æµ‹è¯•
    print(f"\nğŸ¤– Test 3: Individual Agent Task Tests")
    print("-" * 60)
    
    # åˆ›å»ºæµ‹è¯•ä»»åŠ¡
    test_tasks = [
        {
            "role": AgentRole.PROJECT_MANAGER,
            "task": create_task(
                title="é¡¹ç›®éœ€æ±‚åˆ†æ",
                description="ä¸ºä¸€ä¸ªç®€å•çš„å¾…åŠäº‹é¡¹åº”ç”¨åˆ¶å®šé¡¹ç›®è®¡åˆ’ï¼ŒåŒ…æ‹¬æŠ€æœ¯é€‰å‹ã€æ—¶é—´çº¿å’Œé£é™©è¯„ä¼°",
                agent_role=AgentRole.PROJECT_MANAGER,
                tech_requirements=[TechStack.PYTHON_FASTAPI, TechStack.VUE_JS],
                priority=TaskPriority.HIGH
            )
        },
        {
            "role": AgentRole.BACKEND_DEVELOPER,
            "task": create_task(
                title="APIæ¥å£è®¾è®¡",
                description="è®¾è®¡ä¸€ä¸ªç®€å•çš„ç”¨æˆ·è®¤è¯APIï¼ŒåŒ…æ‹¬æ³¨å†Œã€ç™»å½•å’ŒJWT tokenéªŒè¯",
                agent_role=AgentRole.BACKEND_DEVELOPER,
                tech_requirements=[TechStack.PYTHON_FASTAPI],
                priority=TaskPriority.MEDIUM
            )
        }
    ]
    
    task_results = []
    
    for test_case in test_tasks:
        role = test_case["role"]
        task = test_case["task"]
        
        print(f"\nğŸ­ Testing {role.value}")
        print(f"ğŸ“‹ Task: {task.title}")
        
        if role in orchestrator_free.agents:
            agent = orchestrator_free.agents[role]
            
            try:
                # æ‰§è¡Œä»»åŠ¡
                result = await agent.execute_task(task)
                
                if result["success"]:
                    print(f"âœ… Task completed successfully")
                    print(f"ğŸ“ Output preview: {result['output'][:100]}...")
                    
                    metadata = result.get("metadata", {})
                    tokens_used = metadata.get("tokens_used", 0)
                    cost = metadata.get("estimated_cost", 0)
                    model_used = metadata.get("model_used", "Unknown")
                    
                    print(f"ğŸ”¢ Tokens used: {tokens_used}")
                    print(f"ğŸ’° Estimated cost: ${cost:.6f}")
                    print(f"ğŸ¤– Model used: {model_used}")
                    
                    task_results.append({
                        "role": role.value,
                        "success": True,
                        "tokens": tokens_used,
                        "cost": cost,
                        "model": model_used
                    })
                else:
                    print(f"âŒ Task failed: {result.get('error', 'Unknown error')}")
                    task_results.append({
                        "role": role.value,
                        "success": False,
                        "error": result.get('error', 'Unknown error')
                    })
                    
            except Exception as e:
                print(f"âŒ Exception during task execution: {e}")
                task_results.append({
                    "role": role.value,
                    "success": False,
                    "error": str(e)
                })
        else:
            print(f"âŒ Agent {role.value} not available")
    
    # Test 4: é¡¹ç›®æ‰§è¡Œæµ‹è¯•ï¼ˆå°è§„æ¨¡ï¼‰
    print(f"\nğŸ—ï¸ Test 4: Mini Project Execution")
    print("-" * 60)
    
    mini_project_config = ProjectConfig(
        name="OpenRouteræµ‹è¯•é¡¹ç›®",
        description="ä½¿ç”¨OpenRouteré›†æˆçš„ç®€å•APIé¡¹ç›®æµ‹è¯•",
        tech_stack=[TechStack.PYTHON_FASTAPI],
        target_platform=PlatformType.API,
        complexity=ProjectComplexity.SIMPLE,
        requirements=[
            "ç®€å•çš„ç”¨æˆ·API",
            "åŸºç¡€é”™è¯¯å¤„ç†",
            "APIæ–‡æ¡£"
        ],
        priority=TaskPriority.MEDIUM
    )
    
    print(f"ğŸ“‹ Project: {mini_project_config.name}")
    print(f"ğŸ¯ Platform: {mini_project_config.target_platform.value}")
    print(f"ğŸ”§ Tech Stack: {', '.join([tech.value for tech in mini_project_config.tech_stack])}")
    
    try:
        # æ‰§è¡Œå°å‹é¡¹ç›®ï¼ˆé™åˆ¶ä»»åŠ¡æ•°é‡ä»¥èŠ‚çœæˆæœ¬ï¼‰
        project_result = await orchestrator_free.execute_project(mini_project_config)
        
        if project_result["success"]:
            print(f"âœ… Mini project completed successfully!")
            print(f"â±ï¸ Execution time: {project_result['execution_time']}")
            print(f"ğŸ“Š Tasks completed: {project_result['tasks_completed']}/{project_result['total_tasks']}")
            print(f"ğŸ“ˆ Success rate: {project_result['success_rate']}")
        else:
            print(f"âŒ Mini project failed: {project_result.get('error', 'Unknown error')}")
            
    except Exception as e:
        print(f"âŒ Exception during project execution: {e}")
    
    # Test 5: æˆæœ¬å’Œæ€§èƒ½ç»Ÿè®¡
    print(f"\nğŸ“Š Test 5: Cost & Performance Statistics")
    print("-" * 60)
    
    agent_stats = orchestrator_free.get_agent_stats()
    
    print(f"ğŸ¤– Total Agents: {agent_stats['summary']['total_agents']}")
    print(f"ğŸ”¢ Total Tokens Used: {agent_stats['summary']['total_tokens_used']:,}")
    print(f"ğŸ’° Total Cost: ${agent_stats['summary']['total_cost_usd']:.6f}")
    print(f"ğŸ†“ Using Free Models: {agent_stats['summary']['prefer_free_models']}")
    
    # æ˜¾ç¤ºå„ä¸ªAgentçš„ç»Ÿè®¡
    print(f"\nğŸ“‹ Individual Agent Statistics:")
    for agent_role, stats in agent_stats["individual_agents"].items():
        if stats.get("tasks_completed", 0) > 0:
            print(f"  ğŸ­ {agent_role}:")
            print(f"     Tasks: {stats['tasks_completed']}")
            print(f"     Tokens: {stats['total_tokens_used']:,}")
            print(f"     Cost: ${stats['total_cost_usd']:.6f}")
            print(f"     Avg/Task: {stats['average_tokens_per_task']:.1f} tokens")
    
    # Test 6: å…è´¹ vs ä»˜è´¹æ¨¡å‹å¯¹æ¯”
    print(f"\nâš¡ Test 6: Free vs Premium Model Comparison")
    print("-" * 60)
    
    print("ğŸ†“ Free Models Summary:")
    free_cost = agent_stats['summary']['total_cost_usd']
    free_tokens = agent_stats['summary']['total_tokens_used']
    print(f"   Total Cost: ${free_cost:.6f}")
    print(f"   Total Tokens: {free_tokens:,}")
    
    # ç®€å•ä¼°ç®—ä»˜è´¹æ¨¡å‹æˆæœ¬ï¼ˆå‡è®¾æ¯”å…è´¹æ¨¡å‹è´µ10å€ï¼‰
    estimated_premium_cost = free_cost * 10 if free_cost > 0 else 0.01
    print(f"\nğŸ’ Estimated Premium Models Cost: ${estimated_premium_cost:.6f}")
    print(f"ğŸ’° Savings with Free Models: ${estimated_premium_cost - free_cost:.6f}")
    
    # æœ€ç»ˆæ€»ç»“
    print(f"\n" + "=" * 80)
    print("ğŸ‰ OpenRouter AI Agent System Integration Test Summary")
    print("=" * 80)
    
    successful_tasks = sum(1 for result in task_results if result["success"])
    total_tasks = len(task_results)
    
    print(f"ğŸ”‘ API Key: Valid and working")
    print(f"ğŸ¤– Agents Initialized: {len(orchestrator_free.agents)}")
    print(f"ğŸ”— Successful Connections: {successful_connections}/{len(connection_results)}")
    print(f"âœ… Task Success Rate: {successful_tasks}/{total_tasks}")
    print(f"ğŸ”¢ Total Tokens Used: {agent_stats['summary']['total_tokens_used']:,}")
    print(f"ğŸ’° Total Cost: ${agent_stats['summary']['total_cost_usd']:.6f}")
    print(f"â° Test Time: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
    
    # æ¨èé…ç½®
    print(f"\nğŸ’¡ Recommended Configuration:")
    print(f"   âœ“ Use OpenRouter: True")
    print(f"   âœ“ Prefer Free Models: True (for development/testing)")
    print(f"   âœ“ Available Models: 325+ models through OpenRouter")
    print(f"   âœ“ Cost Optimization: Free models available for most tasks")
    
    overall_success = successful_connections > 0 and successful_tasks > 0
    
    if overall_success:
        print(f"\nğŸŠ OpenRouter integration is fully functional!")
        print(f"ğŸš€ Ready for production use with multi-agent coordination")
    else:
        print(f"\nâš ï¸ OpenRouter integration needs attention")
        print(f"ğŸ”§ Check API configuration and network connectivity")
    
    return overall_success

async def main():
    """ä¸»æµ‹è¯•å‡½æ•°"""
    try:
        success = await test_openrouter_agent_system()
        return 0 if success else 1
    except Exception as e:
        print(f"ğŸ’¥ Test failed with exception: {e}")
        import traceback
        traceback.print_exc()
        return 1

if __name__ == "__main__":
    print("ğŸ§ª OpenRouter AI Agent System Integration Test")
    print("Testing complete integration with multi-agent coordination")
    print("=" * 80)
    
    exit_code = asyncio.run(main())
    print(f"\nğŸ Test completed with exit code: {exit_code}")
    sys.exit(exit_code)